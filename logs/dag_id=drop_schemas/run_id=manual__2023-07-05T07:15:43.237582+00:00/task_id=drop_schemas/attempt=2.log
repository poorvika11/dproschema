[2023-07-05T07:24:50.506+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: drop_schemas.drop_schemas manual__2023-07-05T07:15:43.237582+00:00 [queued]>
[2023-07-05T07:24:50.519+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: drop_schemas.drop_schemas manual__2023-07-05T07:15:43.237582+00:00 [queued]>
[2023-07-05T07:24:50.520+0000] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2023-07-05T07:24:50.522+0000] {taskinstance.py:1284} INFO - Starting attempt 2 of 2
[2023-07-05T07:24:50.523+0000] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2023-07-05T07:24:50.542+0000] {taskinstance.py:1304} INFO - Executing <Task(SnowflakeOperator): drop_schemas> on 2023-07-05 07:15:43.237582+00:00
[2023-07-05T07:24:50.549+0000] {standard_task_runner.py:55} INFO - Started process 1791 to run task
[2023-07-05T07:24:50.554+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'drop_schemas', 'drop_schemas', 'manual__2023-07-05T07:15:43.237582+00:00', '--job-id', '17', '--raw', '--subdir', 'DAGS_FOLDER/task.py', '--cfg-path', '/tmp/tmpx09borcz']
[2023-07-05T07:24:50.559+0000] {standard_task_runner.py:83} INFO - Job 17: Subtask drop_schemas
[2023-07-05T07:24:50.662+0000] {task_command.py:389} INFO - Running <TaskInstance: drop_schemas.drop_schemas manual__2023-07-05T07:15:43.237582+00:00 [running]> on host 4d829e7f4f94
[2023-07-05T07:24:50.764+0000] {taskinstance.py:1513} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=drop_schemas
AIRFLOW_CTX_TASK_ID=drop_schemas
AIRFLOW_CTX_EXECUTION_DATE=2023-07-05T07:15:43.237582+00:00
AIRFLOW_CTX_TRY_NUMBER=2
AIRFLOW_CTX_DAG_RUN_ID=manual__2023-07-05T07:15:43.237582+00:00
[2023-07-05T07:24:50.767+0000] {sql.py:253} INFO - Executing: 
SELECT 'DROP SCHEMA IF EXISTS "' || schema_name || '";' AS drop_statement
FROM information_schema.schemata
WHERE schema_name NOT IN (
    SELECT DISTINCT TABLE_SCHEMA 
    FROM information_schema.tables
    WHERE LAST_QUERY_ID IS NOT NULL
      AND LAST_QUERY_END_TIME >= CURRENT_TIMESTAMP() - INTERVAL '30 DAY'
)
[2023-07-05T07:24:50.782+0000] {base.py:73} INFO - Using connection ID 'snowflake_connection' for task execution.
[2023-07-05T07:24:51.823+0000] {logging_mixin.py:137} WARNING - /home/***/.local/lib/python3.7/site-packages/snowflake/connector/options.py:109 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-07-05T07:24:51.929+0000] {base.py:73} INFO - Using connection ID 'snowflake_connection' for task execution.
[2023-07-05T07:24:51.933+0000] {connection.py:300} INFO - Snowflake Connector for Python Version: 3.0.4, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-07-05T07:24:51.935+0000] {connection.py:1013} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-07-05T07:24:51.937+0000] {connection.py:1030} INFO - Setting use_openssl_only mode to False
[2023-07-05T07:24:56.665+0000] {local_task_job.py:82} ERROR - Received SIGTERM. Terminating subprocesses
[2023-07-05T07:24:56.689+0000] {process_utils.py:133} INFO - Sending Signals.SIGTERM to group 1791. PIDs of all processes in the group: [1791]
[2023-07-05T07:24:56.691+0000] {process_utils.py:84} INFO - Sending the signal Signals.SIGTERM to group 1791
[2023-07-05T07:24:56.692+0000] {taskinstance.py:1483} ERROR - Received SIGTERM. Terminating subprocesses.
[2023-07-05T07:24:56.737+0000] {taskinstance.py:1772} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/common/sql/operators/sql.py", line 261, in execute
    return_last=self.return_last,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/snowflake/hooks/snowflake.py", line 373, in run
    with closing(self.get_conn()) as conn:
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/snowflake/hooks/snowflake.py", line 296, in get_conn
    conn = connector.connect(**conn_config)
  File "/home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/__init__.py", line 51, in Connect
    return SnowflakeConnection(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/connection.py", line 319, in __init__
    self.connect(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/connection.py", line 590, in connect
    self.__open_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/connection.py", line 860, in __open_connection
    self.authenticate_with_retry(self.auth_class)
  File "/home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/connection.py", line 1127, in authenticate_with_retry
    self._authenticate(auth_instance)
  File "/home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/connection.py", line 1165, in _authenticate
    session_parameters=self._session_parameters,
  File "/home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/auth/_auth.py", line 255, in authenticate
    socket_timeout=auth_timeout,
  File "/home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/network.py", line 729, in _post_request
    _include_retry_params=_include_retry_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/network.py", line 819, in fetch
    session, method, full_url, headers, data, retry_ctx, **kwargs
  File "/home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/network.py", line 941, in _request_exec_wrapper
    raise e
  File "/home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/network.py", line 868, in _request_exec_wrapper
    **kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/network.py", line 1138, in _request_exec
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/network.py", line 1045, in _request_exec
    auth=SnowflakeAuth(token),
  File "/home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/vendored/requests/sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/vendored/requests/sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/vendored/requests/adapters.py", line 498, in send
    chunked=chunked,
  File "/home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/vendored/urllib3/connectionpool.py", line 710, in urlopen
    chunked=chunked,
  File "/home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/vendored/urllib3/connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "/home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/vendored/urllib3/connectionpool.py", line 1042, in _validate_conn
    conn.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/vendored/urllib3/connection.py", line 363, in connect
    self.sock = conn = self._new_conn()
  File "/home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/vendored/urllib3/connection.py", line 175, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File "/home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/vendored/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1485, in signal_handler
    raise AirflowException("Task received SIGTERM signal")
airflow.exceptions.AirflowException: Task received SIGTERM signal
[2023-07-05T07:24:56.760+0000] {taskinstance.py:1327} INFO - Marking task as FAILED. dag_id=drop_schemas, task_id=drop_schemas, execution_date=20230705T071543, start_date=20230705T072450, end_date=20230705T072456
[2023-07-05T07:24:56.820+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 17 for task drop_schemas (Task received SIGTERM signal; 1791)
[2023-07-05T07:24:56.916+0000] {process_utils.py:79} INFO - Process psutil.Process(pid=1791, status='terminated', exitcode=1, started='07:24:49') (1791) terminated with exit code 1
[2023-07-05T07:24:56.922+0000] {local_task_job.py:159} INFO - Task exited with return code 143
[2023-07-05T07:24:57.031+0000] {taskinstance.py:2582} INFO - 0 downstream tasks scheduled from follow-on schedule check
